---
# These strings are constants used by the dispatcher to select functionality at runtime
# Choose the model and dataset
# model_and_data: CIFAR_RESNET18
model_and_data: CIFAR_SPARSYFED_RESNET18
# model_and_data: CIFAR_SPARSYFED_NO_ACT_RESNET18
# model_and_data: CIFAR_ZEROFL_RESNET18
# model_and_data: CIFAR_FLASH_RESNET18

# Choose the train, test and server fed_eval functions
# train_structure: CIFAR_RESNET18
train_structure: CIFAR_RESNET18_PRUNE
# train_structure: CIFAR_RESNET18_FIXED_PRUNE

alpha: 1.0
sparsity: 0.0
mask: 0.0

# Client fit config
fit_config:
  # Net does not require any configuration
  net_config: {}
  # Dataloader requires batch_size
  dataloader_config:
    batch_size: 16
  # The train function requires epochs and learning_rate
  run_config:
    epochs: 1
    learning_rate: 0.1
    final_learning_rate: 0.01
    warmup: 0
    tot_rounds: 700
  # No extra config
  extra: {window_training: false, in_out_eval: false, mask: false, noise: 0}

# Client eval config
eval_config:
  net_config: {}
  # The testing function batch size can be as high as the GPU supports
  dataloader_config:
    batch_size: 256
  # Unlike train, the mnist train function takes no parameters?
  run_config: {}
  extra: {window_training: false, mask: false}

# Configuration for the federated testing function
# Follows the same conventions as the client config
fed_test_config:
  net_config: {}
  # The testing function batch size can be as high as the GPU supports
  dataloader_config:
    batch_size: 256
  # Unlike train, the mnist train function takes no parameters?
  run_config: {}
  extra: {}

# Configuration instructions for initial parameter 
# generation
net_config_initial_parameters: {}

# The names of metrics you wish to aggregate
fit_metrics: [train_loss, train_accuracy, learning_rate]

evaluate_metrics: [test_accuracy, sparsity]
