---
# These strings are constants used by the dispatcher to select functionality at runtime
# Please implement all behaviour in the task-level dispatch.py file and then add the dispatch functions to the top-level dispatch.py
# Choose the model and dataset
model_and_data: SPEECH_RESNET18
# model_and_data: SPEECH_PP
# model_and_data: SPEECH_PPSWAT
# model_and_data: SPEECH_ZERO

# Choose the train, test and server fed_eval functions
train_structure: SPEECH_RESNET18_PRUNE
# train_structure: SPEECH_RESNET18_FLASH

alpha: 1.25
sparsity: 0.9
mask: 0.0

# Client fit config
fit_config:
  # Net does not require any configuration
  net_config: {}
  # Dataloader requires batch_size
  dataloader_config:
    batch_size: 16
  # The train function requires epochs and learning_rate
  run_config:
    epochs: 1
    learning_rate: 0.1
    final_learning_rate: 0.01
    warmup: 0
    tot_rounds: 500
  # No extra config
  extra: {in_out_eval: false, mask: false}

# Client eval config
eval_config:
  net_config: {}
  # The testing function batch size can be as high as the GPU supports
  dataloader_config:
    batch_size: 256
  # Unlike train, the mnist train function takes no parameters?
  run_config: {}
  extra: {window_training: false, mask: false}

# Configuration for the federated testing function
# Follows the same conventions as the client config
fed_test_config:
  net_config: {}
  # The testing function batch size can be as high as the GPU supports
  dataloader_config:
    batch_size: 256
  # Unlike train, the mnist train function takes no parameters?
  run_config: {}
  extra: {}

# Configuration instructions for initial parameter 
# generation
net_config_initial_parameters: {}

# The names of metrics you wish to aggregate
fit_metrics:
  - train_loss
  - train_accuracy
  - learning_rate
  # - update_rate

evaluate_metrics:
  - test_accuracy
  - nomask_test_accuracy
  - nomask_loss
  # - noalpha_loss
  # - noalpha_test_accuracy
  - sparsity
  - test_time
