{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from fvcore.nn import FlopCountAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_features=1000, out_features=10)\n",
    "        self.conv = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=1)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x) -> Tensor:\n",
    "        conv_output_sparse = self.act(self.conv(x)).flatten(1).to_sparse()\n",
    "        w_t_sparse = self.fc.weight.to_sparse()\n",
    "        b_sparse = self.fc.bias.to_sparse()\n",
    "        out = torch.sparse.mm(conv_output_sparse, w_t_sparse)\n",
    "        out_bias = torch.sparse.addmm(out, b_sparse)\n",
    "        # out_bias = torch.add(out, self.fc.bias)\n",
    "        # out_bias = F.linear(conv_output, w_t_sparse, b_sparse)\n",
    "        # out_bias = F.linear(conv_output.to_sparse(), self.fc.weight, self.fc.bias)\n",
    "        # out_bias = torch.sparse.addmm(self.fc.bias, conv_output.to_sparse(), self.fc.weight.t())\n",
    "        return out_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TestModel()\n",
    "# model.fc.weight.data.fill_(0)\n",
    "inputs = (torch.randn((1, 3, 10, 10)),)\n",
    "flops = FlopCountAnalysis(model, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::to_sparse encountered 1 time(s)\n",
      "Unsupported operator aten::_sparse_addmm encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "fc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flops.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flops.total(\"fc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flops.by_operator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flops.by_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flops.by_module_and_operator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparsyfed-bJTUCg0v-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
