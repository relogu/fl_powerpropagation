---
# These strings are constants used by the dispatcher to select functionality at runtime
# Please implement all behaviour in the task-level dispatch.py file and then add the dispatch functions to the top-level dispatch.py
# Choose the model and dataset
# model_and_data: SPEECH_RN18
# model_and_data: SPEECH_SPARSYFED_NA_RN18
model_and_data: SPEECH_SPARSYFED_RN18
# model_and_data: SPEECH_ZEROFL_RN18

# Choose the train, test and server fed_eval functions
train_structure: SPEECH_RN18_PRUNE
# train_structure: SPEECH_RN18_FIX

alpha: 1.0
sparsity: 0.0
mask: 0.0

# Client fit config
fit_config:
  # Net does not require any configuration
  net_config: {}
  # Dataloader requires batch_size
  dataloader_config:
    batch_size: 16
  # The train function requires epochs and learning_rate
  run_config:
    epochs: 1
    learning_rate: 0.5
    final_learning_rate: 0.01
    warmup: 0
    tot_rounds: 700
  # No extra config
  extra: {in_out_eval: false, mask: false}

# Client eval config
eval_config:
  net_config: {}
  # The testing function batch size can be as high as the GPU supports
  dataloader_config:
    batch_size: 256
  # Unlike train, the mnist train function takes no parameters?
  run_config: {}
  extra: {window_training: false, mask: false}

# Configuration for the federated testing function
# Follows the same conventions as the client config
fed_test_config:
  net_config: {}
  # The testing function batch size can be as high as the GPU supports
  dataloader_config:
    batch_size: 256
  # Unlike train, the mnist train function takes no parameters?
  run_config: {}
  extra: {}

# Configuration instructions for initial parameter 
# generation
net_config_initial_parameters: {}

# The names of metrics you wish to aggregate
fit_metrics: [train_loss, train_accuracy, learning_rate]

evaluate_metrics: [test_accuracy, sparsity]
